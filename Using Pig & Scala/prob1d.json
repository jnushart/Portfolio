{"paragraphs":[{"text":"val oshkosh = spark.read.format(\"csv\").option(\"header\", true).option(\"inferSchema\", true).load(\"/user/maria_dev/final/Oshkosh/OshkoshWeather.csv\")\nval oshkosh2 = oshkosh.withColumn(\"merge\", concat_ws(\"-\", $\"Year\", $\"Month\", $\"Day\", $\"TimeCST\"))\n  .withColumn(\"date\", to_timestamp(unix_timestamp($\"merge\", \"yyyy-MM-dd-hh:mm aa\").cast(\"timestamp\")))\n  .withColumn(\"timestamp\", unix_timestamp($\"date\"))\n  .withColumn(\"timeOfHour\", ($\"timestamp\" % 3600))\n  .withColumn(\"hourstamp\", ($\"timestamp\" - $\"timeOfHour\"))\n  .withColumn(\"hourofday\", (($\"hourstamp\" % 86400)/3600))\n  .withColumn(\"merge2\", concat_ws(\"-\", $\"Year\", $\"Month\", $\"Day\"))\n  .withColumn(\"finaldate\", to_date(unix_timestamp($\"merge\", \"yyyy-MM-dd\").cast(\"timestamp\")))\n  .drop(\"merge\")\n  .drop(\"merge2\")\nval oshkosh3 = oshkosh2.filter($\"TemperatureF\" > -9990)\nval tempavg = oshkosh3.groupBy($\"hourstamp\".as(\"min_hour\"), $\"finaldate\".as(\"finaldate1\"), $\"hourofday\").agg(avg($\"TemperatureF\").as(\"avg_value\"))\nval tempMin = oshkosh3.groupBy($\"finaldate\").agg(min($\"TemperatureF\").as(\"min_value\"))\nval tempTopByJoin = tempavg.join(broadcast(tempMin),\n    ($\"finaldate1\" === $\"finaldate\") && ($\"avg_value\" === $\"min_value\"))\n  .drop(\"min_hour\")\n  .drop(\"min_value\")\ntempTopByJoin.createOrReplaceTempView(\"answerTable\")\nspark.sqlContext.sql(\"SELECT DISTINCT hourofday, count(*) AS COUNT FROM answerTable GROUP BY hourofday ORDER BY COUNT DESC\").show","user":"anonymous","dateUpdated":"2020-04-30T02:57:09+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"oshkosh: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 14 more fields]\noshkosh2: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 20 more fields]\noshkosh3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 20 more fields]\ntempavg: org.apache.spark.sql.DataFrame = [min_hour: bigint, finaldate1: date ... 2 more fields]\ntempMin: org.apache.spark.sql.DataFrame = [finaldate: date, min_value: double]\ntempTopByJoin: org.apache.spark.sql.DataFrame = [finaldate1: date, hourofday: double ... 2 more fields]\n+---------+-----+\n|hourofday|COUNT|\n+---------+-----+\n|      5.0| 1305|\n|     23.0| 1264|\n|      4.0|  986|\n|      6.0|  941|\n|      3.0|  648|\n|      0.0|  526|\n|      1.0|  488|\n|      2.0|  471|\n|     22.0|  449|\n|      7.0|  343|\n|     21.0|  218|\n|     20.0|  100|\n|      8.0|   74|\n|     19.0|   67|\n|     18.0|   52|\n|      9.0|   32|\n|     17.0|   30|\n|     10.0|   17|\n|     16.0|   15|\n|     15.0|   10|\n+---------+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1588122948882_752937896","id":"20200429-011548_602042908","dateCreated":"2020-04-29T01:15:48+0000","dateStarted":"2020-04-30T02:57:09+0000","dateFinished":"2020-04-30T02:57:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5177"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588215123200_879978308","id":"20200430-025203_37285122","dateCreated":"2020-04-30T02:52:03+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:5178"}],"name":"prob1d","id":"2F9EGQM8E","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}